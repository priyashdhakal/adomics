{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-06 00:37:47.716075: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-01-06 00:37:47.755277: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-01-06 00:37:47.755313: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-01-06 00:37:47.756466: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-01-06 00:37:47.763755: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-01-06 00:37:47.765867: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-06 00:37:48.639560: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.constraints import MaxNorm\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import cohen_kappa_score, matthews_corrcoef, recall_score, precision_score, f1_score, accuracy_score\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.regularizers import l2\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_PATH = 'data/ROSMAP/'\n",
    "methy_path = os.path.join(BASE_PATH,'methy.csv')\n",
    "mirna_path = os.path.join(BASE_PATH,'mirna.csv')\n",
    "mrna_path = os.path.join(BASE_PATH,'mrna.csv')\n",
    "if not os.path.exists(methy_path) or not os.path.exists(mirna_path) or not os.path.exists(mrna_path):\n",
    "    raise Exception('File not exists!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(351, 202) (351, 202) (351, 202)\n"
     ]
    }
   ],
   "source": [
    "methy_df = pd.read_csv(methy_path, index_col=0)\n",
    "mirna_df = pd.read_csv(mirna_path, index_col=0)\n",
    "mrna_df = pd.read_csv(mrna_path, index_col=0)\n",
    "print(methy_df.shape, mirna_df.shape, mrna_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cg00095526</th>\n",
       "      <th>cg00174500</th>\n",
       "      <th>cg00398048</th>\n",
       "      <th>cg00597076</th>\n",
       "      <th>cg00727590</th>\n",
       "      <th>cg00745735</th>\n",
       "      <th>cg00754253</th>\n",
       "      <th>cg00777121</th>\n",
       "      <th>cg00830029</th>\n",
       "      <th>cg00840516</th>\n",
       "      <th>...</th>\n",
       "      <th>cg25947945</th>\n",
       "      <th>cg26143719</th>\n",
       "      <th>cg26984805</th>\n",
       "      <th>cg27016307</th>\n",
       "      <th>cg27091787</th>\n",
       "      <th>cg27120999</th>\n",
       "      <th>cg27146152</th>\n",
       "      <th>cg27243140</th>\n",
       "      <th>Label</th>\n",
       "      <th>Split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.598012</td>\n",
       "      <td>0.529952</td>\n",
       "      <td>0.232042</td>\n",
       "      <td>0.704232</td>\n",
       "      <td>0.372624</td>\n",
       "      <td>0.875641</td>\n",
       "      <td>0.613827</td>\n",
       "      <td>0.398456</td>\n",
       "      <td>0.440477</td>\n",
       "      <td>0.569050</td>\n",
       "      <td>...</td>\n",
       "      <td>0.609315</td>\n",
       "      <td>0.531111</td>\n",
       "      <td>0.654504</td>\n",
       "      <td>0.472625</td>\n",
       "      <td>0.537309</td>\n",
       "      <td>0.277879</td>\n",
       "      <td>0.396369</td>\n",
       "      <td>0.322722</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.586543</td>\n",
       "      <td>0.579997</td>\n",
       "      <td>0.299445</td>\n",
       "      <td>0.664964</td>\n",
       "      <td>0.362864</td>\n",
       "      <td>0.890115</td>\n",
       "      <td>0.512908</td>\n",
       "      <td>0.340878</td>\n",
       "      <td>0.444445</td>\n",
       "      <td>0.525837</td>\n",
       "      <td>...</td>\n",
       "      <td>0.596808</td>\n",
       "      <td>0.511755</td>\n",
       "      <td>0.647161</td>\n",
       "      <td>0.484705</td>\n",
       "      <td>0.544367</td>\n",
       "      <td>0.363328</td>\n",
       "      <td>0.385566</td>\n",
       "      <td>0.335697</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.634034</td>\n",
       "      <td>0.477586</td>\n",
       "      <td>0.274113</td>\n",
       "      <td>0.713400</td>\n",
       "      <td>0.313916</td>\n",
       "      <td>0.886373</td>\n",
       "      <td>0.659061</td>\n",
       "      <td>0.364959</td>\n",
       "      <td>0.416631</td>\n",
       "      <td>0.504891</td>\n",
       "      <td>...</td>\n",
       "      <td>0.558276</td>\n",
       "      <td>0.519758</td>\n",
       "      <td>0.685954</td>\n",
       "      <td>0.467882</td>\n",
       "      <td>0.534083</td>\n",
       "      <td>0.236898</td>\n",
       "      <td>0.447631</td>\n",
       "      <td>0.311407</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.557265</td>\n",
       "      <td>0.549105</td>\n",
       "      <td>0.352897</td>\n",
       "      <td>0.685386</td>\n",
       "      <td>0.385889</td>\n",
       "      <td>0.976137</td>\n",
       "      <td>0.573691</td>\n",
       "      <td>0.376060</td>\n",
       "      <td>0.445305</td>\n",
       "      <td>0.534050</td>\n",
       "      <td>...</td>\n",
       "      <td>0.644223</td>\n",
       "      <td>0.477909</td>\n",
       "      <td>0.662154</td>\n",
       "      <td>0.529904</td>\n",
       "      <td>0.526594</td>\n",
       "      <td>0.341244</td>\n",
       "      <td>0.427688</td>\n",
       "      <td>0.350926</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.587819</td>\n",
       "      <td>0.517650</td>\n",
       "      <td>0.309449</td>\n",
       "      <td>0.692494</td>\n",
       "      <td>0.348508</td>\n",
       "      <td>0.901882</td>\n",
       "      <td>0.620659</td>\n",
       "      <td>0.326728</td>\n",
       "      <td>0.454191</td>\n",
       "      <td>0.515826</td>\n",
       "      <td>...</td>\n",
       "      <td>0.572207</td>\n",
       "      <td>0.521734</td>\n",
       "      <td>0.655149</td>\n",
       "      <td>0.519307</td>\n",
       "      <td>0.494170</td>\n",
       "      <td>0.275346</td>\n",
       "      <td>0.408960</td>\n",
       "      <td>0.310059</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 202 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   cg00095526  cg00174500  cg00398048  cg00597076  cg00727590  cg00745735  \\\n",
       "1    0.598012    0.529952    0.232042    0.704232    0.372624    0.875641   \n",
       "2    0.586543    0.579997    0.299445    0.664964    0.362864    0.890115   \n",
       "3    0.634034    0.477586    0.274113    0.713400    0.313916    0.886373   \n",
       "4    0.557265    0.549105    0.352897    0.685386    0.385889    0.976137   \n",
       "5    0.587819    0.517650    0.309449    0.692494    0.348508    0.901882   \n",
       "\n",
       "   cg00754253  cg00777121  cg00830029  cg00840516  ...  cg25947945  \\\n",
       "1    0.613827    0.398456    0.440477    0.569050  ...    0.609315   \n",
       "2    0.512908    0.340878    0.444445    0.525837  ...    0.596808   \n",
       "3    0.659061    0.364959    0.416631    0.504891  ...    0.558276   \n",
       "4    0.573691    0.376060    0.445305    0.534050  ...    0.644223   \n",
       "5    0.620659    0.326728    0.454191    0.515826  ...    0.572207   \n",
       "\n",
       "   cg26143719  cg26984805  cg27016307  cg27091787  cg27120999  cg27146152  \\\n",
       "1    0.531111    0.654504    0.472625    0.537309    0.277879    0.396369   \n",
       "2    0.511755    0.647161    0.484705    0.544367    0.363328    0.385566   \n",
       "3    0.519758    0.685954    0.467882    0.534083    0.236898    0.447631   \n",
       "4    0.477909    0.662154    0.529904    0.526594    0.341244    0.427688   \n",
       "5    0.521734    0.655149    0.519307    0.494170    0.275346    0.408960   \n",
       "\n",
       "   cg27243140  Label  Split  \n",
       "1    0.322722    0.0    1.0  \n",
       "2    0.335697    1.0    1.0  \n",
       "3    0.311407    1.0    1.0  \n",
       "4    0.350926    0.0    1.0  \n",
       "5    0.310059    0.0    1.0  \n",
       "\n",
       "[5 rows x 202 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mirna_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(351, 201) (351, 200)\n"
     ]
    }
   ],
   "source": [
    "methy_df_wol = methy_df.drop('Label', axis=1)\n",
    "mirna_df_wol = mirna_df.drop('Label', axis=1)\n",
    "mrna_df_wol = mrna_df.drop('Label', axis=1)\n",
    "methy_df_wos = methy_df_wol.drop('Split', axis=1)\n",
    "mirna_df_wos = mirna_df_wol.drop('Split', axis=1)\n",
    "mrna_df_wos = mrna_df_wol.drop('Split', axis=1)\n",
    "\n",
    "combined_df = pd.concat([methy_df_wos, mirna_df_wos, mrna_df_wos], axis=1)\n",
    "combined_df['Label'] = methy_df['Label']\n",
    "combined_df['Split'] = methy_df['Split']\n",
    "print(mrna_df_wol.shape, mrna_df_wos.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(245, 200) (245, 200) (245, 200)\n",
      "(106, 200) (106, 200) (106, 200)\n",
      "(245,) (245,) (245,)\n",
      "(106,) (106,) (106,)\n"
     ]
    }
   ],
   "source": [
    "def get_train_test(df):\n",
    "    train_df = df[df['Split'] == 1].drop('Split', axis=1)\n",
    "    test_df = df[df['Split'] == 0].drop('Split', axis=1)\n",
    "    y_train = train_df.pop('Label')\n",
    "    y_test = test_df.pop('Label')\n",
    "    return train_df.values, test_df.values, y_train.values, y_test.values\n",
    "\n",
    "mirna_train, mirna_test, mirna_y,mirna_y_test = get_train_test(mirna_df)\n",
    "methy_train, methy_test, methy_y,methy_y_test = get_train_test(methy_df)\n",
    "mrna_train, mrna_test, mrna_y,mrna_y_test = get_train_test(mrna_df)\n",
    "print(mirna_train.shape, methy_train.shape, mrna_train.shape)\n",
    "print(mirna_test.shape, methy_test.shape, mrna_test.shape)\n",
    "print(mirna_y.shape, methy_y.shape, mrna_y.shape)\n",
    "print(mirna_y_test.shape, methy_y_test.shape, mrna_y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_dataset(train, test):\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(train)\n",
    "    train = scaler.transform(train)\n",
    "    test = scaler.transform(test)\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(245, 200) (245, 200) (245, 200)\n",
      "(106, 200) (106, 200) (106, 200)\n",
      "(245,) (245,) (245,)\n",
      "(106,) (106,) (106,)\n"
     ]
    }
   ],
   "source": [
    "mirna_train, mirna_test = scale_dataset(mirna_train, mirna_test)\n",
    "methy_train, methy_test = scale_dataset(methy_train, methy_test)\n",
    "mrna_train, mrna_test = scale_dataset(mrna_train, mrna_test)\n",
    "print(mirna_train.shape, methy_train.shape, mrna_train.shape)\n",
    "print(mirna_test.shape, methy_test.shape, mrna_test.shape)\n",
    "print(mirna_y.shape, methy_y.shape, mrna_y.shape)\n",
    "print(mirna_y_test.shape, methy_y_test.shape, mrna_y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([10, 1])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class FeatureExtractor(tf.keras.models.Model):\n",
    "    def __init__(self, input_shape):\n",
    "        super().__init__()\n",
    "        self.input_layer = Input(shape=input_shape)\n",
    "        self.dense_1 = Dense(32, activation='relu')\n",
    "        self.dense_2 = Dense(16, activation='relu')\n",
    "    def call(self, x):\n",
    "        x = self.dense_1(x)\n",
    "        x = self.dense_2(x)\n",
    "        return x\n",
    "\n",
    "class CombinationNetwork(tf.keras.models.Model):\n",
    "\n",
    "    @staticmethod\n",
    "    def get_dense_block(output_dim, activation = 'relu', dropout = 0.5):\n",
    "        return Sequential([\n",
    "            Dense(output_dim, activation = activation),\n",
    "            Dropout(dropout),\n",
    "        ])\n",
    "    def __init__(self, input_1_shape, input_2_shape, input_3_shape):\n",
    "        super().__init__()\n",
    "        self.ft1 = FeatureExtractor(input_1_shape)\n",
    "        self.ft2 = FeatureExtractor(input_2_shape)\n",
    "        self.ft3 = FeatureExtractor(input_3_shape)\n",
    "        self.fc1 = CombinationNetwork.get_dense_block(32)\n",
    "        self.fc2 = CombinationNetwork.get_dense_block(16)\n",
    "        self.out = Dense(1, activation = 'sigmoid')\n",
    "    \n",
    "    def call(self, x_arr):\n",
    "        x1,x2,x3 = x_arr\n",
    "        x1 = self.ft1(x1)\n",
    "        x2 = self.ft2(x2)\n",
    "        x3 = self.ft3(x3)\n",
    "        x = tf.concat([x1,x2,x3], axis=1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        return self.out(x)\n",
    "input_1 = tf.convert_to_tensor(np.random.random((10,200)))\n",
    "input_2 = tf.convert_to_tensor(np.random.random((10,200)))\n",
    "input_3 = tf.convert_to_tensor(np.random.random((10,200)))\n",
    "model = CombinationNetwork((200,), (200,), (200,))\n",
    "model([input_1, input_2, input_3]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(mirna_data, methy_data, mrna_data, y, batch_size):\n",
    "    for i in range(0, len(mirna_data), batch_size):\n",
    "        mirna_batch = mirna_data[i:i+batch_size]\n",
    "        methy_batch = methy_data[i:i+batch_size]\n",
    "        mrna_batch = mrna_data[i:i+batch_size]\n",
    "        y_batch = y[i:i+batch_size]\n",
    "        yield [mirna_batch, methy_batch, mrna_batch], y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['loss', 'accuracy']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.metrics_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 136ms/step - loss: 0.6294 - accuracy: 0.6562\n",
      "Epoch: 0, Step: 0, Loss: [0.6293992400169373, 0.65625]\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.6757 - accuracy: 0.5189\n",
      "Validation: Epoch: 0, Step: 0, Loss: [0.6757262349128723, 0.5188679099082947]\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.5967 - accuracy: 0.7188\n",
      "Epoch: 1, Step: 0, Loss: [0.5966951251029968, 0.71875]\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6564 - accuracy: 0.6038\n",
      "Validation: Epoch: 1, Step: 0, Loss: [0.6563862562179565, 0.6037735939025879]\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5716 - accuracy: 0.7188\n",
      "Epoch: 2, Step: 0, Loss: [0.5715963244438171, 0.71875]\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6446 - accuracy: 0.6415\n",
      "Validation: Epoch: 2, Step: 0, Loss: [0.6446277499198914, 0.6415094137191772]\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.5540 - accuracy: 0.7500\n",
      "Epoch: 3, Step: 0, Loss: [0.5539609789848328, 0.75]\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6286 - accuracy: 0.6792\n",
      "Validation: Epoch: 3, Step: 0, Loss: [0.6285722255706787, 0.6792452931404114]\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5348 - accuracy: 0.7500\n",
      "Epoch: 4, Step: 0, Loss: [0.5348324775695801, 0.75]\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6168 - accuracy: 0.6981\n",
      "Validation: Epoch: 4, Step: 0, Loss: [0.616780161857605, 0.698113203048706]\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5195 - accuracy: 0.7812\n",
      "Epoch: 5, Step: 0, Loss: [0.5194947719573975, 0.78125]\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6065 - accuracy: 0.7075\n",
      "Validation: Epoch: 5, Step: 0, Loss: [0.6065242886543274, 0.7075471878051758]\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5020 - accuracy: 0.7812\n",
      "Epoch: 6, Step: 0, Loss: [0.502042293548584, 0.78125]\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.5934 - accuracy: 0.7075\n",
      "Validation: Epoch: 6, Step: 0, Loss: [0.5933781266212463, 0.7075471878051758]\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.4777 - accuracy: 0.8438\n",
      "Epoch: 7, Step: 0, Loss: [0.4777429699897766, 0.84375]\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.5819 - accuracy: 0.7358\n",
      "Validation: Epoch: 7, Step: 0, Loss: [0.58188796043396, 0.7358490824699402]\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.4556 - accuracy: 0.8438\n",
      "Epoch: 8, Step: 0, Loss: [0.4555574059486389, 0.84375]\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5721 - accuracy: 0.7075\n",
      "Validation: Epoch: 8, Step: 0, Loss: [0.5721004009246826, 0.7075471878051758]\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.4281 - accuracy: 0.9062\n",
      "Epoch: 9, Step: 0, Loss: [0.4280851483345032, 0.90625]\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.5680 - accuracy: 0.7075\n",
      "Validation: Epoch: 9, Step: 0, Loss: [0.5680400133132935, 0.7075471878051758]\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.4067 - accuracy: 0.9062\n",
      "Epoch: 10, Step: 0, Loss: [0.40665408968925476, 0.90625]\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.5609 - accuracy: 0.7358\n",
      "Validation: Epoch: 10, Step: 0, Loss: [0.5609146952629089, 0.7358490824699402]\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.3815 - accuracy: 0.9062\n",
      "Epoch: 11, Step: 0, Loss: [0.3814987540245056, 0.90625]\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.5431 - accuracy: 0.6887\n",
      "Validation: Epoch: 11, Step: 0, Loss: [0.5430903434753418, 0.6886792182922363]\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.3380 - accuracy: 0.9062\n",
      "Epoch: 12, Step: 0, Loss: [0.3379986882209778, 0.90625]\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.5304 - accuracy: 0.7547\n",
      "Validation: Epoch: 12, Step: 0, Loss: [0.530448317527771, 0.7547169923782349]\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.3066 - accuracy: 0.9375\n",
      "Epoch: 13, Step: 0, Loss: [0.3066377341747284, 0.9375]\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.5182 - accuracy: 0.7453\n",
      "Validation: Epoch: 13, Step: 0, Loss: [0.5181774497032166, 0.7452830076217651]\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.2734 - accuracy: 0.9375\n",
      "Epoch: 14, Step: 0, Loss: [0.2734311819076538, 0.9375]\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.5098 - accuracy: 0.7453\n",
      "Validation: Epoch: 14, Step: 0, Loss: [0.5098237991333008, 0.7452830076217651]\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.2356 - accuracy: 0.9375\n",
      "Epoch: 15, Step: 0, Loss: [0.23561227321624756, 0.9375]\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.5152 - accuracy: 0.7736\n",
      "Validation: Epoch: 15, Step: 0, Loss: [0.5151792764663696, 0.7735849022865295]\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.2006 - accuracy: 0.9375\n",
      "Epoch: 16, Step: 0, Loss: [0.20057319104671478, 0.9375]\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.5137 - accuracy: 0.7547\n",
      "Validation: Epoch: 16, Step: 0, Loss: [0.5137160420417786, 0.7547169923782349]\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.1567 - accuracy: 1.0000\n",
      "Epoch: 17, Step: 0, Loss: [0.15673953294754028, 1.0]\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5142 - accuracy: 0.7358\n",
      "Validation: Epoch: 17, Step: 0, Loss: [0.5142477750778198, 0.7358490824699402]\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1228 - accuracy: 1.0000\n",
      "Epoch: 18, Step: 0, Loss: [0.12284485995769501, 1.0]\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5255 - accuracy: 0.7547\n",
      "Validation: Epoch: 18, Step: 0, Loss: [0.5255029201507568, 0.7547169923782349]\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0959 - accuracy: 1.0000\n",
      "Epoch: 19, Step: 0, Loss: [0.09591200947761536, 1.0]\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.5273 - accuracy: 0.7075\n",
      "Validation: Epoch: 19, Step: 0, Loss: [0.5273299217224121, 0.7075471878051758]\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0752 - accuracy: 1.0000\n",
      "Epoch: 20, Step: 0, Loss: [0.07522527873516083, 1.0]\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.5223 - accuracy: 0.7453\n",
      "Validation: Epoch: 20, Step: 0, Loss: [0.522320032119751, 0.7452830076217651]\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0598 - accuracy: 1.0000\n",
      "Epoch: 21, Step: 0, Loss: [0.0597611665725708, 1.0]\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.5328 - accuracy: 0.7642\n",
      "Validation: Epoch: 21, Step: 0, Loss: [0.5328018665313721, 0.7641509175300598]\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0477 - accuracy: 1.0000\n",
      "Epoch: 22, Step: 0, Loss: [0.04773829132318497, 1.0]\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.5597 - accuracy: 0.7642\n",
      "Validation: Epoch: 22, Step: 0, Loss: [0.5596623420715332, 0.7641509175300598]\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0360 - accuracy: 1.0000\n",
      "Epoch: 23, Step: 0, Loss: [0.035987742245197296, 1.0]\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5786 - accuracy: 0.7453\n",
      "Validation: Epoch: 23, Step: 0, Loss: [0.5786429643630981, 0.7452830076217651]\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0251 - accuracy: 1.0000\n",
      "Epoch: 24, Step: 0, Loss: [0.025121264159679413, 1.0]\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6186 - accuracy: 0.7264\n",
      "Validation: Epoch: 24, Step: 0, Loss: [0.6186236143112183, 0.7264150977134705]\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0171 - accuracy: 1.0000\n",
      "Epoch: 25, Step: 0, Loss: [0.01712041348218918, 1.0]\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6663 - accuracy: 0.7264\n",
      "Validation: Epoch: 25, Step: 0, Loss: [0.6662725210189819, 0.7264150977134705]\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0127 - accuracy: 1.0000\n",
      "Epoch: 26, Step: 0, Loss: [0.01273241639137268, 1.0]\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6770 - accuracy: 0.7547\n",
      "Validation: Epoch: 26, Step: 0, Loss: [0.6769623756408691, 0.7547169923782349]\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0095 - accuracy: 1.0000\n",
      "Epoch: 27, Step: 0, Loss: [0.009457062929868698, 1.0]\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6743 - accuracy: 0.7830\n",
      "Validation: Epoch: 27, Step: 0, Loss: [0.6743215322494507, 0.7830188870429993]\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0069 - accuracy: 1.0000\n",
      "Epoch: 28, Step: 0, Loss: [0.006866772659122944, 1.0]\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7444 - accuracy: 0.7642\n",
      "Validation: Epoch: 28, Step: 0, Loss: [0.7443928122520447, 0.7641509175300598]\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0051 - accuracy: 1.0000\n",
      "Epoch: 29, Step: 0, Loss: [0.005141145549714565, 1.0]\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.7637 - accuracy: 0.7453\n",
      "Validation: Epoch: 29, Step: 0, Loss: [0.7636858224868774, 0.7452830076217651]\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0035 - accuracy: 1.0000\n",
      "Epoch: 30, Step: 0, Loss: [0.003485899418592453, 1.0]\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.7494 - accuracy: 0.7264\n",
      "Validation: Epoch: 30, Step: 0, Loss: [0.7493891716003418, 0.7264150977134705]\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0027 - accuracy: 1.0000\n",
      "Epoch: 31, Step: 0, Loss: [0.0027497897390276194, 1.0]\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.7686 - accuracy: 0.7264\n",
      "Validation: Epoch: 31, Step: 0, Loss: [0.7686289548873901, 0.7264150977134705]\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch: 32, Step: 0, Loss: [0.002155873691663146, 1.0]\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.8098 - accuracy: 0.7264\n",
      "Validation: Epoch: 32, Step: 0, Loss: [0.8098200559616089, 0.7264150977134705]\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch: 33, Step: 0, Loss: [0.0015813549980521202, 1.0]\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.8435 - accuracy: 0.7547\n",
      "Validation: Epoch: 33, Step: 0, Loss: [0.8434565663337708, 0.7547169923782349]\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch: 34, Step: 0, Loss: [0.00120110297575593, 1.0]\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.8616 - accuracy: 0.7830\n",
      "Validation: Epoch: 34, Step: 0, Loss: [0.861617922782898, 0.7830188870429993]\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch: 35, Step: 0, Loss: [0.0010459570912644267, 1.0]\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.8369 - accuracy: 0.7830\n",
      "Validation: Epoch: 35, Step: 0, Loss: [0.836917519569397, 0.7830188870429993]\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 7.8913e-04 - accuracy: 1.0000\n",
      "Epoch: 36, Step: 0, Loss: [0.0007891287095844746, 1.0]\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.7847 - accuracy: 0.7830\n",
      "Validation: Epoch: 36, Step: 0, Loss: [0.7847094535827637, 0.7830188870429993]\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 6.1673e-04 - accuracy: 1.0000\n",
      "Epoch: 37, Step: 0, Loss: [0.0006167314713820815, 1.0]\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.7992 - accuracy: 0.7925\n",
      "Validation: Epoch: 37, Step: 0, Loss: [0.799225926399231, 0.7924528121948242]\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 4.6363e-04 - accuracy: 1.0000\n",
      "Epoch: 38, Step: 0, Loss: [0.0004636319063138217, 1.0]\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.8785 - accuracy: 0.7925\n",
      "Validation: Epoch: 38, Step: 0, Loss: [0.8785208463668823, 0.7924528121948242]\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 4.5878e-04 - accuracy: 1.0000\n",
      "Epoch: 39, Step: 0, Loss: [0.0004587774456012994, 1.0]\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9631 - accuracy: 0.7925\n",
      "Validation: Epoch: 39, Step: 0, Loss: [0.9631010890007019, 0.7924528121948242]\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 4.0619e-04 - accuracy: 1.0000\n",
      "Epoch: 40, Step: 0, Loss: [0.0004061891813762486, 1.0]\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.0259 - accuracy: 0.7925\n",
      "Validation: Epoch: 40, Step: 0, Loss: [1.0259273052215576, 0.7924528121948242]\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 2.9733e-04 - accuracy: 1.0000\n",
      "Epoch: 41, Step: 0, Loss: [0.0002973303780891001, 1.0]\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.1816 - accuracy: 0.7453\n",
      "Validation: Epoch: 41, Step: 0, Loss: [1.1816260814666748, 0.7452830076217651]\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 2.2805e-04 - accuracy: 1.0000\n",
      "Epoch: 42, Step: 0, Loss: [0.0002280511544086039, 1.0]\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.2850 - accuracy: 0.7358\n",
      "Validation: Epoch: 42, Step: 0, Loss: [1.2849876880645752, 0.7358490824699402]\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 1.8524e-04 - accuracy: 1.0000\n",
      "Epoch: 43, Step: 0, Loss: [0.0001852362183853984, 1.0]\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.2436 - accuracy: 0.7358\n",
      "Validation: Epoch: 43, Step: 0, Loss: [1.2436425685882568, 0.7358490824699402]\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 1.3769e-04 - accuracy: 1.0000\n",
      "Epoch: 44, Step: 0, Loss: [0.00013768915960099548, 1.0]\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.0855 - accuracy: 0.7642\n",
      "Validation: Epoch: 44, Step: 0, Loss: [1.0854885578155518, 0.7641509175300598]\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 1.1162e-04 - accuracy: 1.0000\n",
      "Epoch: 45, Step: 0, Loss: [0.00011162295413669199, 1.0]\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.0230 - accuracy: 0.7642\n",
      "Validation: Epoch: 45, Step: 0, Loss: [1.0230218172073364, 0.7641509175300598]\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 8.8224e-05 - accuracy: 1.0000\n",
      "Epoch: 46, Step: 0, Loss: [8.822391828289255e-05, 1.0]\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.0463 - accuracy: 0.7642\n",
      "Validation: Epoch: 46, Step: 0, Loss: [1.0462839603424072, 0.7641509175300598]\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 6.3588e-05 - accuracy: 1.0000\n",
      "Epoch: 47, Step: 0, Loss: [6.358826794894412e-05, 1.0]\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.1060 - accuracy: 0.7736\n",
      "Validation: Epoch: 47, Step: 0, Loss: [1.1059579849243164, 0.7735849022865295]\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 5.4354e-05 - accuracy: 1.0000\n",
      "Epoch: 48, Step: 0, Loss: [5.435395723907277e-05, 1.0]\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.1955 - accuracy: 0.7736\n",
      "Validation: Epoch: 48, Step: 0, Loss: [1.195529818534851, 0.7735849022865295]\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 4.3399e-05 - accuracy: 1.0000\n",
      "Epoch: 49, Step: 0, Loss: [4.3398762500146404e-05, 1.0]\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.2679 - accuracy: 0.7547\n",
      "Validation: Epoch: 49, Step: 0, Loss: [1.2679132223129272, 0.7547169923782349]\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 50\n",
    "for epoch in range(n_epochs):\n",
    "    for step, data in enumerate(generator(mirna_train, methy_train, mrna_train, mirna_y, 32)):\n",
    "        x, y = data\n",
    "        model.train_on_batch(x, y)\n",
    "        if step % 100 == 0:\n",
    "            print('Epoch: {}, Step: {}, Loss: {}'.format(epoch, step, model.evaluate(x, y)))\n",
    "    for step, val_data in enumerate(generator(mirna_test, methy_test, mrna_test, mirna_y_test, 106)):\n",
    "        x_val, y_val = val_data\n",
    "        print('Validation: Epoch: {}, Step: {}, Loss: {}'.format(epoch, step, model.evaluate(x_val, y_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ADomics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
